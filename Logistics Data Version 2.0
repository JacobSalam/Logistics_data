
# encoding = utf-8

import os
import sys
import time
import datetime
import random as r
import csv
'''
    IMPORTANT
    Edit only the validate_input and collect_events functions.
    Do not edit any other part in this file.
    This file is generated only once when creating the modular input.
'''

app_location = os.path.dirname(os.path.dirname(__file__))

def validate_input(helper, definition):
    """Implement your own validation logic to validate the input stanza configurations"""
    # This example accesses the modular input variable
    # number_of_orders_per_day = definition.parameters.get('number_of_orders_per_day', None)
    # std_dev_number_of_orders = definition.parameters.get('std_dev_number_of_orders', None)
    pass

""" Start of the data gen code"""
def collect_events(helper, ew):
    
    """Open all the lookups and save them as lists"""
    with open(os.path.join(app_location, 'lookups', 'clients.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=';')
        clients = [list(row) for row in df][1:]
    with open(os.path.join(app_location, 'lookups', 'product_lookup.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=';')
        products = [list(row) for row in df][1:]
    with open(os.path.join(app_location, 'lookups', 'suppliers.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=';')
        suppliers = [list(row) for row in df][1:]
    with open(os.path.join(app_location, 'lookups', 'depots.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=';')
        depots = [list(row) for row in df][1:]
    with open(os.path.join(app_location, 'lookups', 'crew.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=';')
        crew = [list(row) for row in df][1:]
    with open(os.path.join(app_location, 'lookups', 'recurrent_orders.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=';')
        recurrent_orders = [list(row) for row in df][1:]
        
    """Order counter keeps track of the last order ID, such that on new days it
    will start from this number"""
    if os.path.exists(os.path.join(app_location, 'lookups', 'order_counter.csv')):
        with open(os.path.join(app_location, 'lookups', 'order_counter.csv')) as csvfile:
            df = csv.reader(csvfile, delimiter=',')
            order_counter = int([list(row) for row in df][0][0])

    else:
        order_counter = 0

    """Get todays and yesterdays date"""
    today = datetime.date.today()
    yesterday = today - datetime.timedelta(days=1)

    
    orders_log1 = []
    event_list = []
    
    date = datetime.datetime.now()
    starthourinseconds = 10*60*60
    
    """ 
    If starting from an earlier date, the data which is located in date.csv
    will use to create data from previous days. This updates the today variable
    from before
    """
    with open(os.path.join(app_location, 'order_data', 'date.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=',')
        dates = [list(row) for row in df]
        today = dates[0][0]
    
    """ create a new date variable based of the date.csv, will be used for event
    creation"""
    date_csv = datetime.datetime(int(today[6:8])+2000, int(today[:2]), int(today[3:5]))
    
    """ Convert the time now in to seconds, is used to determine when events are released into splunk """
    def now_to_seconds(date):
        todays_time_in_seconds = int(date.hour) * 60 * 60 + int(date.minute) * 60 + int(date.second) + 7200
        return todays_time_in_seconds
    
    """ seconds can then also be sent back into hours:minutes:seconds and used
    in the event creation for time, the date from date.csv is added to time"""
    def convert(seconds):
        seconds = seconds % (24 * 3600)
        hour = seconds // 3600
        seconds %= 3600
        minutes = seconds // 60
        seconds %= 60

        return date_csv.strftime("%x")+" " + "%d:%02d:%02d" % (hour, minutes, seconds)
    
    with open(os.path.join(app_location, 'client_ai', 'avg_supplier_delivery_accuracy_per_client.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=',')
        product_delivery_accuracy = [list([int(float(ro)*100) for ro in row]) for row in df]
    with open(os.path.join(app_location, 'client_ai', 'clients_preference_vectors.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=',')
        preference_vectors = [list([int(ro) for ro in row]) for row in df]
    with open(os.path.join(app_location, 'client_ai', 'delivery_times.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=',')
        avg_delivery_times = [list([float(ro) for ro in row]) for row in df]
    with open(os.path.join(app_location, 'client_ai', 'nearest_supplier_from_clients.csv')) as csvfile:
        df = csv.reader(csvfile, delimiter=',')
        nearest_suppliers_to_clients = [list([float(ro) for ro in row]) for row in df]
    
    avg_value_prod = 0
    size = 0
    for x in products:
        avg_value_prod += int(x[5])
        size += (float(x[1])*float(x[2])*float(x[3])) / 1000000
    
    avg_value_prod = avg_value_prod/len(products)
    avg_size = size/len(products)
    
    
    def client_ai(client_id):
        [Fast, Local_supportive, Secure, Small, Big, Cheap, Expensive, Promotion_sensitive] = preference_vectors[clientid - 1]
    
        # decision tree
        # 1: Find the suppliers to choose from based of preferences
        # Preference give a higher prob that the supplier will be added to the possible suppliers: 70% chance
        possible_suppliers = []
    
        if sum(preference_vectors[client_id - 1][:3]) > 0:
            if Fast == 1:
                frand = r.randrange(0, 10)
                if frand < 8:
                    times = avg_delivery_times[client_id-1]
                    mintimes = sorted(range(len(times)), key=lambda k: times[k])
                    possible_suppliers.extend(mintimes[:2])
    
            if Local_supportive == 1:
                lrand = r.randrange(0, 10)
                if lrand < 8:
                    distances = nearest_suppliers_to_clients[client_id-1]
                    mindistance = sorted(range(len(distances)), key=lambda k: distances[k])
                    if mindistance[0] not in possible_suppliers:
                        possible_suppliers.append(mindistance[0])
    
            if Secure == 1:
                srand = r.randrange(0, 10)
                if srand < 8:
    
                    accuracy = product_delivery_accuracy[client_id-1]
                    maxaccuracy = sorted(range(len(accuracy)), key=lambda k: accuracy[k])
    
                    # print(maxaccuracy[-1])
                    if maxaccuracy[-1] not in possible_suppliers:
                        possible_suppliers.append(maxaccuracy[-1])
    
    
        if not possible_suppliers:
            possible_suppliers = [0, 1, 2, 3, 4]
    
        subset_products = []
        possible_orders = []
        possible_orders_final = []
    
        for prod in products:
            if int(prod[6]) - 101 in possible_suppliers:
                subset_products.append(prod)
    
        # # Small, Big, Cheap, Expensive, Promotion_sensitive
        if sum(preference_vectors[client_id - 1][3:]) > 0:
    
            if Big == Small:
                for prod in subset_products:
                    possible_orders.append(int(prod[0]))
    
            else:
                if Small == 1:
                    for prod in subset_products:
                        if (float(prod[1])*float(prod[2])*float(prod[3])) / 1000000 < avg_size:
                            possible_orders.append(int(prod[0]))
                            # print(int(prod[0]))
    
                if Big == 1:
                    for prod in subset_products:
                        if (float(prod[1])*float(prod[2])*float(prod[3])) / 1000000 >= avg_size:
                            possible_orders.append(int(prod[0]))
                            # print(int(prod[0]))
    
            # print(possible_orders)
            possible_orders_subset = []
            if Cheap == Expensive:
                for prod in possible_orders:
                    possible_orders_subset.append(prod)
                pass
            else:
                if Cheap == 1:
                    for prod in possible_orders:
    
                        if float(products[prod-30001][5]) < avg_value_prod:
                            possible_orders_subset.append(int(prod))
    
                if Expensive == 1:
                    for prod in possible_orders:
                        # print(float(products[prod - 30001][5]), avg_value_prod)
                        if float(products[prod-30001][5]) >= avg_value_prod:
                            possible_orders_subset.append(int(prod))
            
            if Promotion_sensitive == 1:
                for prod in possible_orders_subset:
                    if products[prod-30001][7] == date_csv.strftime('%A'):
                        possible_orders_final.append(prod)
            else:
                possible_orders_final = possible_orders_subset
    
            # print(possible_orders_final)
    
            if possible_orders_final:
                random_order = r.randrange(0, len(possible_orders_final))
                return possible_orders_final[random_order]
            else:
                return 0
    
        else:
            random_order = r.randrange(0, len(subset_products))
            return int(subset_products[random_order][0])
    

    """ Each time the code is run one of two things can happend. If the event data
    is already created it will run if statement below. This slowly releases the
    saved events to splunk. The elif statement below this if statement only
    creates new data when it is a new day and the event data does not exist. 
    This happens after all data is released to splunk. At this 
    point the code deletes all saved event files (also known as 
    order_data_for_today.csv files) """
    
    if os.path.exists(os.path.join(app_location, 'order_data', 'order_data_for_today1.csv')):
        """ If the days match, open the different order files. The order files 
        are saved seperatly due to the fact that not all events are the same. 
        Some events have supplier_id, crew_id, others don't. Therefor they 
        needed to be saved seperatly."""
        if date_csv <= date:
            fieldname_collect = []
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today1.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data = all[1:]
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today2.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data.extend(all[1:])
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today3.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data.extend(all[1:])
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today4.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data.extend(all[1:])
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today5.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data.extend(all[1:])
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today6.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data.extend(all[1:])
            with open(os.path.join(app_location, 'order_data', 'order_data_for_today7.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                all = [list(row) for row in df]
                fieldnames = all[0]
                for x in range(len(all[1:])):
                    fieldname_collect.append(fieldnames)
                event_data.extend(all[1:])
            
            """Order Datetime are list which match the order data lists but only
            hold the time in seconds format. By using these list we can sort 
            them and return the indexes of the order data which can be released
            based on time"""
            
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today1.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data = [list(row) for row in df]
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today2.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data.extend([list(row) for row in df])
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today3.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data.extend([list(row) for row in df])
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today4.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data.extend([list(row) for row in df])
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today5.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data.extend([list(row) for row in df])
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today6.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data.extend([list(row) for row in df])
            with open(os.path.join(app_location, 'order_data', 'order_datatime_for_today7.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                time_data.extend([list(row) for row in df])
            
            """Row is used to skip events which already have been released to
            splunk and therefor prevents duplicates"""
            
            with open(os.path.join(app_location, 'order_data', 'row.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                row = [list(row) for row in df][0][0]
            
            """ Sort the timedata list and return a list if indexes which show
            which items in the order data list are to be released first"""
            sorted_time_list_indexes = sorted(range(len(time_data)), key=lambda k: time_data[k])
            sorted_time_list = sorted(time_data, key=lambda x: x[0])
    
            time_now = now_to_seconds(date)
            row = int(row)
            
            
            """ Release the events based on time and the ordered time list"""
            for x in range(len(sorted_time_list)):
                """ If all data has been released to splunk, remove the order
                data files"""
                if row == len(event_data)-1:
                    for file in os.listdir(os.path.join(app_location, 'order_data')):
                        if file == "date.csv":
                            mycsv = csv.writer(
                                open(os.path.join(app_location, 'order_data', 'date.csv'), 'w',
                                     newline=''))
                            mycsv.writerows([[(date_csv + datetime.timedelta(days=1)).strftime('%m/%d/%y')]])
    
                            continue
                        os.remove(os.path.join(app_location, 'order_data', str(file)))
    
                    exit()
                
                """ If the order data has been released already, skip it"""
                if x < row:
                    continue
                
                """ Else, release the order data as an event"""
                if int(float(sorted_time_list[x][0])) < time_now or date_csv.strftime('%m/%d') < datetime.datetime.now().strftime('%m/%d')  or date_csv.strftime('%y') <  datetime.datetime.now().strftime('%y'):
                    log = event_data[sorted_time_list_indexes[x]]
                    names = fieldname_collect[sorted_time_list_indexes[x]]

                    e = ""
    
                    for y in range(len(names)):
                        if e != "":
                            e = e+", "
                        e = e + str(names[y]) + "; " + str(log[y]) 
    
                    event = helper.new_event(str(e), time=None, host=None, index=None, source=None, sourcetype=None,
                                         done=True, unbroken=True)
                    ew.write_event(event)

    
                else:
                    break
            """Update the row.csv file"""
            mycsv = csv.writer(
                open(os.path.join(app_location, 'order_data', 'row.csv'), 'w',
                     newline=''))
            mycsv.writerows([[x]])
    
    elif date_csv.strftime('%m/%d') <= datetime.datetime.now().strftime('%m/%d') or date_csv.strftime('%y') < datetime.datetime.now().strftime('%y'):
        """Get a random number of new orders"""
        opt_number_of_orders_per_day = 750
        opt_std_dev_number_of_orders = 250
        
        
        val = date_csv.weekday()
        num_list = [[400, 800], [600,900], [700,1000], [900,1200], [500,700],[400,600],[200,400]]

        num_new_orders = r.randrange(num_list[val][0], num_list[val][1])
    
    
        """
        Create a random probablity for the orders.
        In this case, the products in left will occur more often than right
        """
        p = 10000
        product_probs = []
        shuffle = []
        for x in range(100):
            product_probs.append(x+1)
            shuffle.append(x+1)
    
        r.shuffle(shuffle)
        left = shuffle[:50]
        right = shuffle[50:]
        for x in range(6600):
            product_probs.append(left[r.randrange(0, 50)])
        for x in range(3300):
            product_probs.append(right[r.randrange(0, 50)])

    
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers', 'supplier_orders_for_tomorrow.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers', 'supplier_orders_for_tomorrow.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders_log1_part1 = [list([int(ro) for ro in row]) for row in df]
        else:
            orders_log1_part1 = []
        
        event_list1, event_list2, event_list3, event_list4, event_list5, event_list6, event_list7 = [], [], [], [], [], [], []
        time_list1, time_list2, time_list3, time_list4, time_list5, time_list6, time_list7 = [], [], [], [], [], [], []
    
        starthourinseconds = 10*60*60 # 10 oclock
        starthourinsecondsrecurrent = 8*60*60 # 8 oclock
        close_shop_time = 17*60*60 # 17 oclock
        delivery_van_first_depart_time = 9*60*60 # 9 oclock
        interval_of_van_departures = 2*60*60 # 2 hours

        """Add the recurrent orders to the new orders"""
        time = starthourinseconds
        day_of_the_week = date_csv.strftime('%A')
        # for x in recurrent_orders:
        #     if x[0] == day_of_the_week:
        #         clientid = int(x[1])-10900
        #         product_id = int(x[2])-30000
        #         orders_log1.append([order_counter, clientid, product_id, products[product_id - 1][6], time])
        #         event_list1.append(
        #             {"time": convert(time), "status": "Order Received from Client", "order_id": order_counter,
        #              "client_id": clientid+10900, "product_id": product_id + 30000,
        #              "supplier_id": products[product_id - 1][6]})
        #         time_list1.append([time])
        #         order_counter += 1
        
        # Save the times of the previous orders for each supplier
        order_time = [int(time) for x in range(5)]
        
        """Create new random orders"""
        for n in range(num_new_orders):
            # product_id = product_probs[r.sample(range(10000), 1)[0]]
            clientid = r.randrange(1, 280)
            product_id = client_ai(clientid)
            if product_id == 0:
                continue
            product_id = product_id - 30000
    
            order_time[int(products[product_id - 1][6])-101] += r.randrange(2, 5)*60
            if order_time[int(products[product_id - 1][6])-101] > 86399:
                continue
            orders_log1_part1.append([order_counter, clientid, product_id, products[product_id - 1][6], order_time[int(products[product_id - 1][6])-101]])
            event_list1.append(
                {"time": convert(order_time[int(products[product_id - 1][6])-101]), "status": "Order Received from Client","status_id":501, "order_id": order_counter,
                 "client_id": clientid + 10900, "product_id": product_id + 30000,
                 "supplier_id": products[product_id - 1][6]})
            time_list1.append([order_time[int(products[product_id - 1][6])-101]])
    
            order_counter += 1
            
        # total_orders = len(orders_log1)
        
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers', 'supplier_to_be_processed_for_tomorrow.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers', 'supplier_to_be_processed_for_tomorrow.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders = [list([int(ro) for ro in row]) for row in df]
        else:
            orders = []
        
        supplier_add_to_tomorrow = []
        for i in orders_log1_part1:
            if int(i[4]) > close_shop_time:
                supplier_add_to_tomorrow.append([i[0], i[1], i[2], i[3], starthourinsecondsrecurrent])
            else:
                orders.append(i)
        
        mycsv = csv.writer(open(os.path.join(app_location, 'yesterdays_leftovers','supplier_orders_for_tomorrow.csv'), 'w', newline=''))
        mycsv.writerows(supplier_add_to_tomorrow)
    
        to_be_processed_tomorrow = []
        
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers','to_be_sent_to_nearest_depot_tomorrow.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers','to_be_sent_to_nearest_depot_tomorrow.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders_log1 = [list([int(ro) for ro in row]) for row in df]
        else:
            orders_log1 = []
        
        num_machines = [(2, 4), (5, 8), (4, 5), (3, 5), (2, 4)]
        processtime = [(3.5, 6.5), (2.5, 3.5), (1.5, 4.5), (1.5, 2.5), (2.5, 5.5)]
        
        for sup in suppliers:
            rows = [orders[i] for i in range(len(orders)) if int(orders[i][3]) == int(sup[0])]
            row_id = 0
            machines = r.randrange(num_machines[int(sup[0])-101][0], num_machines[int(sup[0])-101][1])
            # print(num_machines[int(sup[0])-101][0], num_machines[int(sup[0])-101][1])
            # print(sup)
            # print(machines)
            times = [starthourinsecondsrecurrent for i in range(machines)]
            p_time = int(starthourinsecondsrecurrent)
            # 61200 is equivalent to 17 o'clock
            while p_time < close_shop_time and row_id < len(rows):
                for j in range(machines):
                    if row_id < len(rows):
                        if times[j] < p_time and rows[row_id][-1] < p_time and row_id < len(rows):
                            # print("gets here  machine: ", j)
    
                            row = rows[row_id]
                            event_list1.append({"time": convert(p_time),
                                 "status": "Processing Order at Supplier", "status_id":502, "order_id": row[0],
                                 "client_id": row[1] + 10900, "product_id": row[2] + 30000,
                                 "supplier_id": row[3]})
                            time_list1.append([p_time])
    
                            processing_time = r.randrange(float(processtime[int(sup[0])-101][0]) *60, float(processtime[int(sup[0])-101][1])*60)
    
                            t = processing_time + p_time
                            event_list1.append(
                                {"time": convert(t),
                                 "status": "Ready for Transit to Nearest Depot", "status_id":503, "order_id": row[0],
                                 "client_id": row[1] + 10900, "product_id": row[2] + 30000,
                                 "supplier_id": row[3]})
                            time_list1.append([t])
                            orders_log1.append([row[0], row[1], row[2], row[3], t])
                            times[j] = t
                            row_id += 1
                    else:
                        break
                p_time += 1
            if p_time == close_shop_time:
                # print(rows[row_id:])
                for row in rows[row_id:]:
                    to_be_processed_tomorrow.append([row[0], row[1], row[2], row[3], starthourinsecondsrecurrent])
    
        mycsv = csv.writer(open(os.path.join(app_location, 'yesterdays_leftovers','supplier_to_be_processed_for_tomorrow.csv'),'w',newline=''))
        mycsv.writerows(to_be_processed_tomorrow)
        
        
    
        """Open csv's with the distance matrices"""
        with open(os.path.join(app_location, 'lookups', 'nearest_depots_from_suppliers.csv')) as csvfile:
            df = csv.reader(csvfile, delimiter=',')
            nearest_depots = [list(row) for row in df]
    
    
        with open(os.path.join(app_location, 'lookups', 'depot_to_depot_distance.csv')) as csvfile:
            df = csv.reader(csvfile, delimiter=',')
            depot_to_depot_distance = [list(row) for row in df]
    
    
        orders_log2 = []
        to_be_sent_to_nearest_depot_tomorrow = []
    
        # delivery starts at 9 am to depots, and happens every two hours with the last delivery leaving at 5
        d_time = delivery_van_first_depart_time
        while d_time <= close_shop_time:
            for order in orders_log1:
                if d_time - 7200 < order[4] <= d_time:
                    supplierid = order[3]
                    depotid = nearest_depots[int(supplierid) - 101][0]
                    event_list2.append(
                        {"time": convert(d_time), "status": "Product in Transit to Depot","status_id":504, "order_id": order[0],
                         "client_id": order[1] + 10900, "product_id": order[2] + 30000,
                         "supplier_id": supplierid, "depot_id": depotid})
    
                    time_list2.append([d_time])
    
                    depotid = nearest_depots[int(supplierid) - 101][0]
                    distance = nearest_depots[int(supplierid) - 101][1]
                    t = d_time + float(distance) / 60 * 3600
    
                    event_list3.append(
                        {"time": convert(t), "status": "Product Arrived at Nearest depot", "status_id":505, "order_id": order[0],
                         "client_id": order[1] + 10900, "product_id": order[2] + 30000,
                         "supplier_id": supplierid, "depot_id": depotid})
    
                    time_list3.append([t])
    
                    orders_log2.append([order[0], order[1], order[2], order[3], depotid, t])
            d_time += interval_of_van_departures
    
        for order in orders_log1:
            if order[4] > close_shop_time:
                to_be_sent_to_nearest_depot_tomorrow.append([order[0], order[1], order[2], order[3], starthourinsecondsrecurrent])
                # print(order[0], order[1], order[2], order[3], 28800)
    
        mycsv = csv.writer(open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_sent_to_nearest_depot_tomorrow.csv'),'w',newline=''))
        mycsv.writerows(to_be_sent_to_nearest_depot_tomorrow)
        
        
    
        with open(os.path.join(app_location, 'lookups', 'nearest_depots_to_clients.csv')) as csvfile:
            df = csv.reader(csvfile, delimiter=',')
            depot_to_clients_distance = [list(row) for row in df]
    
    
        count = 0
        d = 0
        crew_list_by_depot = [[] for _ in range(10)]
        ordercheck1 = [0 for _ in range(10)]
        ordercheck2 = [0 for _ in range(10)]
    
    
    
        for c in crew:
            crew_id = c[0]
            depotid = int(c[1]) - 201
            seniority = c[2]
            crew_list_by_depot[depotid].append([crew_id, seniority])
        
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_processed_tomorrow_depots.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_processed_tomorrow_depots.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders_log2_part2 = [list([int(ro) for ro in row]) for row in df]
        else:
            orders_log2_part2 = []
    
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_sent_to_next_depots.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_sent_to_next_depots.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders_log3 = [list([int(ro) for ro in row]) for row in df]
        else:
            orders_log3 = []
    
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_processed_tomorrow_final_depots.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_processed_tomorrow_final_depots.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders_log4 = [list([int(ro) for ro in row]) for row in df]
        else:
            orders_log4 = []
        
        
        for order in orders_log2:
            clientid = order[1]
            closest_clients = [float(i) for i in depot_to_clients_distance[clientid - 1]]
            i = closest_clients.index(min(closest_clients))
            depotid_send_to = depots[i][0]
            depotid_current = order[4]
            time = order[5]
    
            if depotid_send_to == depotid_current:
                depotid_to = int(depotid_send_to) - 201
                crew_size = len(crew_list_by_depot[depotid_to])
                crew_choice = r.randrange(0,crew_size)
                crew_id = crew_list_by_depot[depotid_to][crew_choice][0]
                crew_seniority = crew_list_by_depot[depotid_to][crew_choice][1]
                event_list6.append(
                    {"time": convert(time), "status": "Product Arrived at Final Depot", "status_id":509, "order_id": order[0],
                    "client_id": order[1] + 10900, "product_id": order[2] + 30000,
                    "depot_id": order[4]})
                time_list6.append([time])
    
                orders_log4.append([order[0], order[1], order[2], order[4], depotid_send_to, time])
    
            else:
                orders_log2_part2.append([order[0], order[1], order[2], order[4], depotid_send_to, time])
    
        to_be_processed_tomorrow_depots = []
        processtime = [(3.5, 6.5), (2.5, 4.5), (1.5, 2.5)]
        do_not_lose_percentage = [100, 95, 90]
    
        for depot in depots:
    
            rows = [orders_log2_part2[i] for i in range(0, len(orders_log2_part2)) if int(orders_log2_part2[i][3]) == int(depot[0])]
            row_id = 0
            d_time = starthourinsecondsrecurrent
            crew_members = crew_list_by_depot[int(depot[0])-201]
            crew_members = crew_members[:round((len(crew_members)/2))]
    
    
    
            times = [starthourinsecondsrecurrent for i in range(len(crew_members))]
            while d_time < close_shop_time and row_id < len(rows):
                for j in range(len(crew_members)):
                    if row_id < len(rows):
                        if times[j] < d_time and int(rows[row_id][-1]) < d_time:
                            row = rows[row_id]
    
                            event_list4.append({"time": convert(d_time),
                                                "status": "Processing Order at Depot", "status_id":506, "order_id": row[0],
                                                "client_id": row[1] + 10900, "product_id": row[2] + 30000,
                                                "depot_id": row[3], "crew_id": crew_members[j][0]})
    
                            time_list4.append([d_time])
    
                            if r.randrange(1, 101) > do_not_lose_percentage[10 - int(crew_members[j][1])]:
                                row_id += 1
                                times[j] = d_time
                                continue
    
                            processing_time = r.randrange(processtime[int(crew_members[j][1])-8][0]*60, processtime[int(crew_members[j][1])-8][1]*60)
    
                            t = processing_time + d_time
                            event_list4.append(
                                {"time": convert(t),
                                 "status": "Ready for Transit to Final Depot", "status_id":507, "order_id": row[0],
                                 "client_id": row[1] + 10900, "product_id": row[2] + 30000,
                                 "depot_id": row[3], "crew_id": crew_members[j][0]})
                            time_list4.append([t])
                            orders_log3.append([row[0], row[1], row[2], row[3], row[4], t])
                            times[j] = t
                            row_id += 1
                    else:
                        break
                d_time += 1
            if d_time == close_shop_time:
                # print(rows[row_id:])
                for row in rows[row_id:]:
                    to_be_processed_tomorrow_depots.append([row[0], row[1], row[2], row[3], row[4], starthourinsecondsrecurrent])
    
        # print(orders_log3)
    
        mycsv = csv.writer(open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_processed_tomorrow_depots.csv'),'w',newline=''))
        mycsv.writerows(to_be_processed_tomorrow_depots)
    
        to_be_sent_to_next_depots = []
    
        d_time = delivery_van_first_depart_time
        while d_time <= close_shop_time:
            for order in orders_log3:
                if d_time - 7200 < order[5] and order[5] <= d_time:
                    event_list6.append(
                        {"time": convert(d_time), "status": "Product in Transit to Final Depot", "status_id":508, "order_id": order[0],
                         "client_id": order[1] + 10900, "product_id": order[2] + 30000,
                         "depot_id": order[3]})
    
                    time_list6.append([d_time])
    
                    distance = depot_to_depot_distance[int(order[3])-201][int(order[4])-201]
                    t = d_time + float(distance) / 60 * 3600
                    
                    event_list6.append(
                        {"time": convert(t), "status": "Product Arrived at Final Depot", "status_id":509, "order_id": order[0],
                        "client_id": order[1] + 10900, "product_id": order[2] + 30000,
                        "depot_id": order[4]})
                    time_list6.append([t])
    
                    orders_log4.append([order[0], order[1], order[2], order[3], order[4], t])
            d_time += interval_of_van_departures
    
        for order in orders_log3:
            if order[5] > close_shop_time:
                to_be_sent_to_next_depots.append([order[0], order[1], order[2], order[3], order[4], starthourinsecondsrecurrent])
    
        mycsv = csv.writer(open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_sent_to_next_depots.csv'),'w',newline=''))
        mycsv.writerows(to_be_sent_to_next_depots)
    
    
        if os.path.exists(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_delivered_to_clients_tomorrow.csv')):
            with open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_delivered_to_clients_tomorrow.csv')) as csvfile:
                df = csv.reader(csvfile, delimiter=',')
                orders_log5 = [list([int(ro) for ro in row]) for row in df]
        else:
            orders_log5 = []
    
        to_be_processed_tomorrow_final_depots = []

        for depot in depots:
            rows = [orders_log4[i] for i in range(0, len(orders_log4)) if int(orders_log4[i][4]) == int(depot[0])]
            rows = sorted(rows, key=lambda g: g[5])
    
            row_id = 0
            d_time = starthourinsecondsrecurrent
            crew_members = crew_list_by_depot[int(depot[0])-201]
            crew_members = crew_members[round((len(crew_members) / 2)):]
    
            times = [starthourinsecondsrecurrent for i in range(len(crew_members))]
            while d_time < close_shop_time and row_id < len(rows):
                for j in range(len(crew_members)):
                    if row_id < len(rows):
                        if times[j] < d_time and int(rows[row_id][-1]) < d_time:
                            row = rows[row_id]
        
                            event_list4.append({"time": convert(d_time),
                                                "status": "Processing Order for Client Delivery", "status_id":510, "order_id": row[0],
                                                "client_id": row[1] + 10900, "product_id": row[2] + 30000,
                                                "depot_id": row[4], "crew_id": crew_members[j][0]})
                            time_list4.append([d_time])
        
                            if r.randrange(1, 101) > do_not_lose_percentage[10 - int(crew_members[j][1])]:
                                row_id += 1
                                times[j] = d_time
                                continue
        
                            processing_time = r.randrange(processtime[int(crew_members[j][1]) - 8][0] * 60, processtime[int(crew_members[j][1]) - 8][1] * 60)
                            t = processing_time + d_time
                            event_list5.append(
                                {"time": convert(t),
                                 "status": "Product Ready for Client Delivery", "status_id":511, "order_id": row[0],
                                 "client_id": row[1] + 10900, "product_id": row[2] + 30000,
                                 "depot_id": row[4], "crew_id": crew_members[j][0]})
        
                            time_list5.append([t])
                            orders_log5.append([row[0], row[1], row[2], row[4], t])
                            times[j] = t
                            row_id += 1
                    else:
                        break
                d_time += 1
    
            if d_time == close_shop_time:
                for row in rows[row_id:]:
                    to_be_processed_tomorrow_final_depots.append([row[0], row[1], row[2], row[3], row[4], starthourinsecondsrecurrent])
    
        mycsv = csv.writer(open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_processed_tomorrow_final_depots.csv'),'w',newline=''))
        mycsv.writerows(to_be_processed_tomorrow_final_depots)
    
    
        to_be_delivered_to_clients_tomorrow = []
    
        
        
        d_time = delivery_van_first_depart_time
        while d_time <= close_shop_time:
            for order in orders_log5:
                if order[4] > d_time - 7200 and order[4] <= d_time:
                    event_list7.append(
                        {"time": convert(d_time), "status": "Product in Transit to Client", "status_id":512, "order_id": order[0],
                         "client_id": order[1] + 10900, "product_id": order[2] + 30000,
                         "depot_id": order[3]})
    
                    time_list7.append([d_time])
            d_time += interval_of_van_departures
    
        for order in orders_log5:
            if order[4] > close_shop_time:
                to_be_delivered_to_clients_tomorrow.append([order[0], order[1], order[2], order[4], starthourinsecondsrecurrent])
    
        mycsv = csv.writer(
            open(os.path.join(app_location, 'yesterdays_leftovers', 'to_be_delivered_to_clients_tomorrow.csv'),'w',newline=''))
        mycsv.writerows(to_be_delivered_to_clients_tomorrow)
        
        """All events are saved in csv files for later release into splunk"""
        keys = event_list1[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today1.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list1)
        keys = event_list2[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today2.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list2)
        keys = event_list3[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today3.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list3)
        keys = event_list4[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today4.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list4)
        keys = event_list5[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today5.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list5)
        keys = event_list6[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today6.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list6)
        keys = event_list7[0].keys()
        with open(os.path.join(app_location, 'order_data', 'order_data_for_today7.csv'), 'w', newline='')  as output_file:
            dict_writer = csv.DictWriter(output_file, keys)
            dict_writer.writeheader()
            dict_writer.writerows(event_list7)
    
    
    
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today1.csv'), 'w', newline =''))
        mycsv.writerows(time_list1)
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today2.csv'), 'w', newline =''))
        mycsv.writerows(time_list2)
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today3.csv'), 'w', newline =''))
        mycsv.writerows(time_list3)
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today4.csv'), 'w', newline =''))
        mycsv.writerows(time_list4)
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today5.csv'), 'w', newline =''))
        mycsv.writerows(time_list5)
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today6.csv'), 'w', newline =''))
        mycsv.writerows(time_list6)
        mycsv = csv.writer(open(os.path.join(app_location, 'order_data', 'order_datatime_for_today7.csv'), 'w', newline =''))
        mycsv.writerows(time_list7)
    
        mycsv = csv.writer(
            open(os.path.join(app_location, 'order_data', 'row.csv'), 'w',
                 newline=''))
        mycsv.writerows([[0]])
    
        
        mycsv = csv.writer(
        open(os.path.join(app_location, 'lookups', 'order_counter.csv'), 'w',
             newline=''))
        mycsv.writerows([[order_counter]])

        
